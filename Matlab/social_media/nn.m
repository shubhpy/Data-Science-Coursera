function [Y,Xf,Af] = nn(X,~,~)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 27-Feb-2016 12:51:23.
%
% [Y] = myNeuralNetworkFunction(X,~,~) takes these arguments:
%
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = Qx7 matrix, input #1 at timestep ts.
%
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = Qx1 matrix, output #1 at timestep ts.
%
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1_xoffset = [-36191068;-35419974;-36543194;-4947337;-35419902.01212;-136440;-979.35789470637];
x1_step1_gain = [2.74976696624359e-08;5.46714184876759e-08;5.47283042169309e-08;4.04180150084505e-07;5.64638659615402e-08;1.45555969189013e-05;0.00150496835343856];
x1_step1_ymin = -1;

% Layer 1
b1 = [-1.1825369655834308;0.54815119933624479;0.1642413722501819;0.18189200220589957;-0.21249258644080585;-1.1662790187819723;-1.8027062940748126];
IW1_1 = [-1.1564487197068798 0.25872054058425376 0.01415000950377843 1.5745437811195278 -0.73828397691069447 0.64672733732476095 0.8903323368171584;-0.63406153903268447 -0.98378463543739814 -1.0567977081428321 -0.85321636779814269 -1.6235388083797979 0.40830329413193672 0.51062533835802115;-2.0585560669878888 -0.72546242745943712 0.52015511247640012 -0.20769750043981702 -0.21502435679443802 -0.87403937786813812 -0.89603577401399004;-2.4383297939290451 -1.2768434969093967 0.54651619094407888 0.14644989586444956 -0.065068375886484717 -0.28055896355214299 0.62778685180258909;3.2297973832406837 -1.2492836181131406 -0.43992545184737047 0.1875924404464106 0.80150218259901429 0.025479821210532057 1.8603171966080871;-1.0797561742007644 0.47849513430664109 -0.90778010612642157 -0.86781229486841771 -0.19574599746440469 0.13577457675255841 -0.51722830658800212;-0.65868624901967843 0.63663505107618545 -0.91414180656971089 -0.7984102217711001 0.80938931583976392 -0.019424636689398343 -0.66727340507041999];

% Layer 2
b2 = -0.99497501624504792;
LW2_1 = [-1.0029868390565602 0.68148864070437853 -1.536623842167854 -2.1082239463277967 2.6276721697951544 -0.24319819578797103 0.089886116577223382];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX, X = {X}; end;

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
    Q = size(X{1},1); % samples/series
else
    Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS
    
    % Input 1
    X{1,ts} = X{1,ts}';
    Xp1 = mapminmax_apply(X{1,ts},x1_step1_gain,x1_step1_xoffset,x1_step1_ymin);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = logsig_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Output 1
    Y{1,ts} = a2;
    Y{1,ts} = Y{1,ts}';
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX, Y = cell2mat(Y); end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings_gain,settings_xoffset,settings_ymin)
y = bsxfun(@minus,x,settings_xoffset);
y = bsxfun(@times,y,settings_gain);
y = bsxfun(@plus,y,settings_ymin);
end

% Sigmoid Positive Transfer Function
function a = logsig_apply(n)
a = 1 ./ (1 + exp(-n));
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
